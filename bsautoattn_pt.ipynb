{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([60000, 1, 28, 28]), y_train shape: torch.Size([60000])\n",
      "x_test shape: torch.Size([10000, 1, 28, 28]), y_test shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(1000)\n",
    "torch.manual_seed(1000)\n",
    "\n",
    "# Define the dimension\n",
    "dim = 8\n",
    "\n",
    "# Define transformations for the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts images to PyTorch tensors ([0, 255] -> [0.0,1.0])\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 60000  # Load all data at once\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "# Get the data\n",
    "for images, labels in train_loader:\n",
    "    x_train = images  # [60000, 1, 28, 28]\n",
    "    y_train = labels  # [60000]\n",
    "    break\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    x_test = images  # [10000, 1, 28, 28]\n",
    "    y_test = labels  # [10000]\n",
    "    break\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape after conversion: torch.Size([60000, 8, 28, 28])\n",
      "x_test shape after conversion: torch.Size([10000, 8, 28, 28])\n",
      "y_train shape after setting targets: torch.Size([60000, 8, 28, 28])\n",
      "y_test shape after setting targets: torch.Size([10000, 8, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_test_copy = x_test.clone()  # Save a copy of x_test for later use\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "x_train = x_train.view(-1, 1, 28, 28)  # [batch_size, 1, 28, 28]\n",
    "x_test = x_test.view(-1, 1, 28, 28)   \n",
    "\n",
    "# Binarize the images\n",
    "temp_x_train = x_train.clone()\n",
    "temp_x_train[temp_x_train > 0.5] = 1\n",
    "temp_x_train[temp_x_train <= 0.5] = 0\n",
    "\n",
    "temp_x_test = x_test.clone()\n",
    "temp_x_test[temp_x_test > 0.5] = 1\n",
    "temp_x_test[temp_x_test <= 0.5] = 0\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.view(-1, 28*28)\n",
    "x_test = x_test.view(-1, 28*28)\n",
    "\n",
    "# Save labels before any modification\n",
    "y_train_save = y_train.clone()\n",
    "y_test_save = y_test.clone()\n",
    "\n",
    "# Add random noise to the training data\n",
    "np.random.seed(1000)\n",
    "a = (np.random.rand(x_train.shape[0], x_train.shape[1]) > 0.3).astype(float)\n",
    "a = torch.from_numpy(a).float()\n",
    "x_train = torch.max(a, x_train)\n",
    "\n",
    "# Convert each input into 8 dimensions\n",
    "def convert_to_8dim(x, dim=8):\n",
    "    batch_size = x.size(0)\n",
    "    height_width = int(np.sqrt(x.size(1)))  # Calculate original image dimensions (28x28)\n",
    "    \n",
    "    # Create a new tensor with [batch_size, dim, height, width]\n",
    "    x_new = torch.zeros(batch_size, dim, height_width, height_width)\n",
    "    \n",
    "    a2 = (x * ((2**dim) - 1e-10)).int()\n",
    "    for i in range(dim):\n",
    "        x_new[:, i, :, :] = (a2 % 2).view(batch_size, height_width, height_width)\n",
    "        a2 = a2 // 2\n",
    "        \n",
    "    return x_new\n",
    "\n",
    "x_train = convert_to_8dim(x_train, dim)\n",
    "x_test = convert_to_8dim(x_test, dim)\n",
    "\n",
    "print(f\"x_train shape after conversion: {x_train.shape}\")\n",
    "print(f\"x_test shape after conversion: {x_test.shape}\")\n",
    "\n",
    "# Set targets to inputs (autoencoder) AFTER conversion\n",
    "y_train = x_train.clone()\n",
    "y_test = x_test.clone()\n",
    "\n",
    "print(f\"y_train shape after setting targets: {y_train.shape}\")\n",
    "print(f\"y_test shape after setting targets: {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        #self.activation = nn.LeakyReLU()\n",
    "        self.activation = nn.Mish()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.activation(self.conv(x))\n",
    "\n",
    "\n",
    "class AutoEncoderWithAttention(nn.Module):\n",
    "    def __init__(self, input_channels=8):\n",
    "        super(AutoEncoderWithAttention, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Mish(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Mish(),\n",
    "            nn.Conv2d(64, 128, kernel_size=7),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "\n",
    "        # Residual block\n",
    "        self.res_block = ResidualBlock(128)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=7),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Mish(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Mish(),\n",
    "            nn.ConvTranspose2d(32, input_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_intermediate=False):\n",
    "        # Encoder\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # Residual connection\n",
    "        x = self.res_block(x)\n",
    "        \n",
    "        if return_intermediate:\n",
    "            return x\n",
    "        \n",
    "        # Decoder\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def clamp_weights(self):\n",
    "        # Enforce non-negative weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                m.weight.data.clamp_(0)\n",
    "    \n",
    "    def reconstruct_image(self, x_out):\n",
    "        x_out2 = x_out.view(-1, 28, 28, self.input_channels)\n",
    "        x_out3 = sum([x_out2[:, :, :, i] * (2 ** i) for i in range(self.input_channels)]) / 256\n",
    "        x_out3 = x_out3.view(-1, 28*28)\n",
    "        return x_out3\n",
    "\n",
    "# Instantiate the model with 8 input channels\n",
    "model = AutoEncoderWithAttention(input_channels=8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4055472273627917\n",
      "Epoch [2/10], Loss: 0.2638849398245414\n",
      "Epoch [3/10], Loss: 0.17421555231014887\n",
      "Epoch [4/10], Loss: 0.12613746711363394\n",
      "Epoch [5/10], Loss: 0.09907564883430799\n",
      "Epoch [6/10], Loss: 0.08193866452823083\n",
      "Epoch [7/10], Loss: 0.07183853377277652\n",
      "Epoch [8/10], Loss: 0.05304829193279147\n",
      "Epoch [9/10], Loss: 0.04119696816429496\n",
      "Epoch [10/10], Loss: 0.032978070387616756\n",
      "Shape of intermediate outputs: (10000, 128, 1, 1)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.clamp_weights()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader)}\")\n",
    "\n",
    "# Extract intermediate outputs for visualization\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_mid = model(x_test, return_intermediate=True)\n",
    "test_mid_np = test_mid.cpu().numpy()\n",
    "\n",
    "print(f\"Shape of intermediate outputs: {test_mid_np.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Function to display images\n",
    "def imshow(img, title):\n",
    "    img = img * 0.5 + 0.5  # Unnormalize to [0,1]\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)).squeeze(), cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Assume test_loader, model, and device are defined elsewhere\n",
    "\n",
    "# Get a batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "\n",
    "# Get reconstructed images\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "\n",
    "# Display original images\n",
    "plt.figure(figsize=(10, 4))\n",
    "for idx in range(8):\n",
    "    plt.subplot(2, 8, idx+1)\n",
    "    imshow(images[idx], f'Original {labels[idx].item()}')\n",
    "\n",
    "# Display reconstructed images\n",
    "for idx in range(8):\n",
    "    plt.subplot(2, 8, idx+9)\n",
    "    imshow(outputs[idx], 'Reconstructed')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SVD whitening\n",
    "def svd_whiten(X):\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    X_white = np.dot(U, Vt)\n",
    "    return X_white\n",
    "\n",
    "test_mid_np = svd_whiten(test_mid_np)\n",
    "print(f\"Whitened shape: {test_mid_np.shape}\")\n",
    "\n",
    "# PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "test_mid2 = pca.fit_transform(test_mid_np)\n",
    "\n",
    "\n",
    "\n",
    "# Plot PCA results\n",
    "labels = y_test_save.numpy()\n",
    "for i in range(10):\n",
    "    plt.scatter(test_mid2[labels == i, 0], test_mid2[labels == i, 1], s=1, label=f\"Digit {i}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# t-SNE visualization\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3, verbose=1).fit_transform(test_mid_np)\n",
    "for i in range(10):\n",
    "    plt.scatter(X_embedded[labels == i, 0], X_embedded[labels == i, 1], s=1, label=f\"Digit {i}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Fit a robust covariance estimator\n",
    "robust_cov = MinCovDet().fit(test_mid_np)\n",
    "cov = robust_cov.covariance_\n",
    "mea = np.mean(test_mid_np, axis=0)\n",
    "\n",
    "# Function to binarize images\n",
    "def binarized(x_test):\n",
    "    x_test_new = torch.zeros(x_test.size(0), x_test.size(1), dim)\n",
    "    a2 = (x_test * ((2**dim)*1 - 1e-10)).int()\n",
    "    for i in range(dim):\n",
    "        x_test_new[:, :, i] = a2 % 2\n",
    "        a2 = a2 // 2\n",
    "    x_test_new = x_test_new.view(-1, 28*28*dim)\n",
    "    return x_test_new\n",
    "\n",
    "# Generate images by interpolating between two random latent vectors\n",
    "np.random.seed(int(time.time()))\n",
    "n = 2\n",
    "b = (np.floor(np.random.rand(n) * len(x_test))).astype(int)\n",
    "x_test_tempo = x_test[b, :].clone()\n",
    "with torch.no_grad():\n",
    "    test_mid = model(x_test_tempo, return_intermediate=True)\n",
    "\n",
    "test_out_big = np.zeros((28*1, 28*100))\n",
    "for i in range(100):\n",
    "    b2 = np.array([i / 99, 1 - i / 99])\n",
    "    temp = (test_mid * torch.from_numpy(b2).float().view(n, 1)).sum(dim=0).unsqueeze(0)\n",
    "    temp_neg = -temp\n",
    "    temp_cat = torch.cat((temp, temp_neg), dim=1)\n",
    "    with torch.no_grad():\n",
    "        test_out = torch.sigmoid(model.fc_out(temp_cat))\n",
    "    \n",
    "    # Include binarization steps\n",
    "    for repeat in range(5):\n",
    "        a = (np.random.rand(test_out.shape[0], test_out.shape[1]) > 0.4).astype(float)\n",
    "        a = torch.from_numpy(a).float()\n",
    "        test_out = torch.max(a, test_out)\n",
    "        test_out = binarized(test_out)\n",
    "        with torch.no_grad():\n",
    "            test_out = model(test_out)\n",
    "    \n",
    "    test_out_img = model.reconstruct_image(test_out)\n",
    "    test_out_img = test_out_img.cpu().numpy().reshape(28, 28)\n",
    "    test_out_big[0*28:(0+1)*28, i*28:(i+1)*28] = test_out_img\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.imshow(test_out_big, cmap='gray')\n",
    "plt.title('Interpolation between two images')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate images from random latent vectors\n",
    "np.random.seed(int(time.time()))\n",
    "n = 1\n",
    "with torch.no_grad():\n",
    "    test_mid2 = np.random.multivariate_normal(mea + (2 * np.random.rand(100) - 1), cov, size=1)\n",
    "    test_mid = torch.from_numpy(test_mid2).float()\n",
    "\n",
    "test_out_big = np.zeros((28*1, 28*100))\n",
    "for i in range(100):\n",
    "    temp = test_mid\n",
    "    temp_neg = -temp\n",
    "    temp_cat = torch.cat((temp, temp_neg), dim=1)\n",
    "    with torch.no_grad():\n",
    "        test_out = torch.sigmoid(model.fc_out(temp_cat))\n",
    "    \n",
    "    # Include binarization steps\n",
    "    for repeat in range(5):\n",
    "        a = (np.random.rand(test_out.shape[0], test_out.shape[1]) > 0.4).astype(float)\n",
    "        a = torch.from_numpy(a).float()\n",
    "        test_out = torch.max(a, test_out)\n",
    "        test_out = binarized(test_out)\n",
    "        with torch.no_grad():\n",
    "            test_out = model(test_out)\n",
    "    \n",
    "    test_out_img = model.reconstruct_image(test_out)\n",
    "    test_out_img = test_out_img.cpu().numpy().reshape(28, 28)\n",
    "    test_out_big[0*28:(0+1)*28, i*28:(i+1)*28] = test_out_img\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.imshow(test_out_big, cmap='gray')\n",
    "plt.title('Generated images from random latent vectors')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
