{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([60000, 1, 28, 28]), y_train shape: torch.Size([60000])\n",
      "x_test shape: torch.Size([10000, 1, 28, 28]), y_test shape: torch.Size([10000])\n",
      "x_train shape after conversion: torch.Size([60000, 6272])\n",
      "x_test shape after conversion: torch.Size([10000, 6272])\n",
      "y_train shape after setting targets: torch.Size([60000, 6272])\n",
      "y_test shape after setting targets: torch.Size([10000, 6272])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(1000)\n",
    "torch.manual_seed(1000)\n",
    "\n",
    "# Define the dimension\n",
    "dim = 8\n",
    "\n",
    "# Define transformations for the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts images to PyTorch tensors ([0, 255] -> [0.0,1.0])\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 60000  # Load all data at once\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "# Get the data\n",
    "for images, labels in train_loader:\n",
    "    x_train = images  # [60000, 1, 28, 28]\n",
    "    y_train = labels  # [60000]\n",
    "    break\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    x_test = images  # [10000, 1, 28, 28]\n",
    "    y_test = labels  # [10000]\n",
    "    break\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "x_test_copy = x_test.clone()  # Save a copy of x_test for later use\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Binarize the images\n",
    "temp_x_train = x_train.clone()\n",
    "temp_x_train[temp_x_train > 0.5] = 1\n",
    "temp_x_train[temp_x_train <= 0.5] = 0\n",
    "\n",
    "temp_x_test = x_test.clone()\n",
    "temp_x_test[temp_x_test > 0.5] = 1\n",
    "temp_x_test[temp_x_test <= 0.5] = 0\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.view(-1, 28*28)\n",
    "x_test = x_test.view(-1, 28*28)\n",
    "\n",
    "# Save labels before any modification\n",
    "y_train_save = y_train.clone()\n",
    "y_test_save = y_test.clone()\n",
    "\n",
    "# Add random noise to the training data\n",
    "np.random.seed(1000)\n",
    "a = (np.random.rand(x_train.shape[0], x_train.shape[1]) > 0.3).astype(float)\n",
    "a = torch.from_numpy(a).float()\n",
    "x_train = torch.max(a, x_train)\n",
    "\n",
    "# Convert each input into 8 dimensions\n",
    "def convert_to_8dim(x, dim=8):\n",
    "    x_new = torch.zeros(x.size(0), x.size(1), dim)\n",
    "    a2 = (x * ((2**dim)*1 - 1e-10)).int()\n",
    "    for i in range(dim):\n",
    "        x_new[:, :, i] = a2 % 2\n",
    "        a2 = a2 // 2\n",
    "    x_new = x_new.view(-1, 28*28*dim)\n",
    "    return x_new\n",
    "\n",
    "x_train = convert_to_8dim(x_train, dim)\n",
    "x_test = convert_to_8dim(x_test, dim)\n",
    "\n",
    "print(f\"x_train shape after conversion: {x_train.shape}\")\n",
    "print(f\"x_test shape after conversion: {x_test.shape}\")\n",
    "\n",
    "# Set targets to inputs (autoencoder) AFTER conversion\n",
    "y_train = x_train.clone()\n",
    "y_test = x_test.clone()\n",
    "\n",
    "print(f\"y_train shape after setting targets: {y_train.shape}\")\n",
    "print(f\"y_test shape after setting targets: {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        #self.activation = nn.LeakyReLU()\n",
    "        self.activtaion = nn.Mish()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.activation(self.conv(x))\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Mish(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.Mish(),\n",
    "            nn.Conv2d(64, 128, kernel_size=7),\n",
    "        )\n",
    "        \n",
    "        # Residual block\n",
    "        self.res_block = ResidualBlock(128)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=7),\n",
    "            nn.Mish(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Mish(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.res_block(x)  # Residual connection\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def clamp_weights(self):\n",
    "        # Enforce non-negative weights\n",
    "        for m in self.nonneg_modules:\n",
    "            m.weight.data.clamp_(0)\n",
    "    \n",
    "    def reconstruct_image(self, x_out):\n",
    "        x_out2 = x_out.view(-1, 28, 28, self.dim)\n",
    "        x_out3 = sum([x_out2[:, :, :, i] * (2 ** i) for i in range(self.dim)]) / 256\n",
    "        x_out3 = x_out3.view(-1, 28*28)\n",
    "        return x_out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiate the model, define the optimizer and loss function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoencoder\u001b[49m()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mL1Loss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the model, define the optimizer and loss function\n",
    "model = Autoencoder()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Prepare data loaders for training\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.clamp_weights()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader)}\")\n",
    "\n",
    "# Extract intermediate outputs for visualization\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_mid = model(x_test, return_intermediate=True)\n",
    "test_mid_np = test_mid.cpu().numpy()\n",
    "\n",
    "# SVD whitening\n",
    "def svd_whiten(X):\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    X_white = np.dot(U, Vt)\n",
    "    return X_white\n",
    "\n",
    "test_mid_np = svd_whiten(test_mid_np)\n",
    "print(f\"Whitened shape: {test_mid_np.shape}\")\n",
    "\n",
    "# PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "test_mid2 = pca.fit_transform(test_mid_np)\n",
    "\n",
    "\n",
    "\n",
    "# Plot PCA results\n",
    "labels = y_test_save.numpy()\n",
    "for i in range(10):\n",
    "    plt.scatter(test_mid2[labels == i, 0], test_mid2[labels == i, 1], s=1, label=f\"Digit {i}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# t-SNE visualization\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3, verbose=1).fit_transform(test_mid_np)\n",
    "for i in range(10):\n",
    "    plt.scatter(X_embedded[labels == i, 0], X_embedded[labels == i, 1], s=1, label=f\"Digit {i}\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Fit a robust covariance estimator\n",
    "robust_cov = MinCovDet().fit(test_mid_np)\n",
    "cov = robust_cov.covariance_\n",
    "mea = np.mean(test_mid_np, axis=0)\n",
    "\n",
    "# Function to binarize images\n",
    "def binarized(x_test):\n",
    "    x_test_new = torch.zeros(x_test.size(0), x_test.size(1), dim)\n",
    "    a2 = (x_test * ((2**dim)*1 - 1e-10)).int()\n",
    "    for i in range(dim):\n",
    "        x_test_new[:, :, i] = a2 % 2\n",
    "        a2 = a2 // 2\n",
    "    x_test_new = x_test_new.view(-1, 28*28*dim)\n",
    "    return x_test_new\n",
    "\n",
    "# Generate images by interpolating between two random latent vectors\n",
    "np.random.seed(int(time.time()))\n",
    "n = 2\n",
    "b = (np.floor(np.random.rand(n) * len(x_test))).astype(int)\n",
    "x_test_tempo = x_test[b, :].clone()\n",
    "with torch.no_grad():\n",
    "    test_mid = model(x_test_tempo, return_intermediate=True)\n",
    "\n",
    "test_out_big = np.zeros((28*1, 28*100))\n",
    "for i in range(100):\n",
    "    b2 = np.array([i / 99, 1 - i / 99])\n",
    "    temp = (test_mid * torch.from_numpy(b2).float().view(n, 1)).sum(dim=0).unsqueeze(0)\n",
    "    temp_neg = -temp\n",
    "    temp_cat = torch.cat((temp, temp_neg), dim=1)\n",
    "    with torch.no_grad():\n",
    "        test_out = torch.sigmoid(model.fc_out(temp_cat))\n",
    "    \n",
    "    # Include binarization steps\n",
    "    for repeat in range(5):\n",
    "        a = (np.random.rand(test_out.shape[0], test_out.shape[1]) > 0.4).astype(float)\n",
    "        a = torch.from_numpy(a).float()\n",
    "        test_out = torch.max(a, test_out)\n",
    "        test_out = binarized(test_out)\n",
    "        with torch.no_grad():\n",
    "            test_out = model(test_out)\n",
    "    \n",
    "    test_out_img = model.reconstruct_image(test_out)\n",
    "    test_out_img = test_out_img.cpu().numpy().reshape(28, 28)\n",
    "    test_out_big[0*28:(0+1)*28, i*28:(i+1)*28] = test_out_img\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.imshow(test_out_big, cmap='gray')\n",
    "plt.title('Interpolation between two images')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Generate images from random latent vectors\n",
    "np.random.seed(int(time.time()))\n",
    "n = 1\n",
    "with torch.no_grad():\n",
    "    test_mid2 = np.random.multivariate_normal(mea + (2 * np.random.rand(100) - 1), cov, size=1)\n",
    "    test_mid = torch.from_numpy(test_mid2).float()\n",
    "\n",
    "test_out_big = np.zeros((28*1, 28*100))\n",
    "for i in range(100):\n",
    "    temp = test_mid\n",
    "    temp_neg = -temp\n",
    "    temp_cat = torch.cat((temp, temp_neg), dim=1)\n",
    "    with torch.no_grad():\n",
    "        test_out = torch.sigmoid(model.fc_out(temp_cat))\n",
    "    \n",
    "    # Include binarization steps\n",
    "    for repeat in range(5):\n",
    "        a = (np.random.rand(test_out.shape[0], test_out.shape[1]) > 0.4).astype(float)\n",
    "        a = torch.from_numpy(a).float()\n",
    "        test_out = torch.max(a, test_out)\n",
    "        test_out = binarized(test_out)\n",
    "        with torch.no_grad():\n",
    "            test_out = model(test_out)\n",
    "    \n",
    "    test_out_img = model.reconstruct_image(test_out)\n",
    "    test_out_img = test_out_img.cpu().numpy().reshape(28, 28)\n",
    "    test_out_big[0*28:(0+1)*28, i*28:(i+1)*28] = test_out_img\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.imshow(test_out_big, cmap='gray')\n",
    "plt.title('Generated images from random latent vectors')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test Reconstruction Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original and reconstructed images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    inputs, _ = next(iter(test_loader))\n",
    "    outputs = model(inputs)\n",
    "    outputs_img = model.reconstruct_image(outputs)\n",
    "    inputs_img = model.reconstruct_image(inputs)\n",
    "\n",
    "# Display images\n",
    "n = 5  # Number of images to display\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(n):\n",
    "    # Original images\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(inputs_img[i].cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Reconstructed images\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(outputs_img[i].cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
